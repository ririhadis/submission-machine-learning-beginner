{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvAKGat01Sd"
   },
   "source": [
    "# **Penting**\n",
    "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
    "- Hapus simbol pagar (#) jika Anda menerapkan kriteria tambahan\n",
    "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **1. Import Library**\n",
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.5.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "Downloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-25.5.0 scikit-optimize-0.10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pyaml.exe is installed in 'C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "#Type your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **2. Memuat Dataset dari Hasil Clustering**\n",
    "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "# Gunakan dataset hasil clustering yang memiliki fitur Target\n",
    "# Silakan gunakan dataset data_clustering jika tidak menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "# Silakan gunakan dataset data_clustering_inverse jika menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "df = pd.read_csv('data_clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bCsep0NZ0LUf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmount</th>\n",
       "      <th>TransactionType</th>\n",
       "      <th>Location</th>\n",
       "      <th>Channel</th>\n",
       "      <th>CustomerAge</th>\n",
       "      <th>CustomerOccupation</th>\n",
       "      <th>TransactionDuration</th>\n",
       "      <th>LoginAttempts</th>\n",
       "      <th>AccountBalance</th>\n",
       "      <th>TransactionYear</th>\n",
       "      <th>TotalBalance</th>\n",
       "      <th>TranDurationGroup</th>\n",
       "      <th>CusAgeGroup</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007207</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344039</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195940</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.113995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065680</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>3</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134317</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096016</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006874</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>3</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmount  TransactionType  Location  Channel  CustomerAge  \\\n",
       "0           0.007207                1        36        0     0.838710   \n",
       "1           0.195940                1        15        0     0.806452   \n",
       "2           0.065680                1        23        2     0.016129   \n",
       "3           0.096016                1        33        2     0.129032   \n",
       "4           0.006874                1         1        2     0.145161   \n",
       "\n",
       "   CustomerOccupation  TransactionDuration  LoginAttempts  AccountBalance  \\\n",
       "0                   0             0.244828            0.0        0.336832   \n",
       "1                   0             0.451724            0.0        0.918055   \n",
       "2                   3             0.158621            0.0        0.068637   \n",
       "3                   3             0.051724            0.0        0.569198   \n",
       "4                   3             0.648276            0.0        0.492591   \n",
       "\n",
       "   TransactionYear  TotalBalance  TranDurationGroup  CusAgeGroup  Target  \n",
       "0              0.0      0.344039                3.0          2.0       3  \n",
       "1              0.0      1.113995                2.0          2.0       1  \n",
       "2              0.0      0.134317                3.0          0.0       1  \n",
       "3              0.0      0.665214                3.0          0.0       3  \n",
       "4              0.0      0.499465                1.0          2.0       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama dengan function head.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkPem5eWL2UP"
   },
   "source": [
    "# **3. Data Splitting**\n",
    "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OubAW-7ONKVj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: X_train=(2011, 13), y_train=(2011,)\n",
      "Test set shape: X_test =(503, 13), y_test=(503,)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan train_test_split() untuk melakukan pembagian dataset.\n",
    "#Pisahkan fitur(X) dan target (Y)\n",
    "X = df.drop(columns=['Target'])\n",
    "y = df['Target']\n",
    "\n",
    "#Split data menjadi set pelatihan dan set uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Tampilkan bentuk set pelatihan dan set uji untuk memastikan split\n",
    "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Test set shape: X_test ={X_test.shape}, y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVPbB03CMhTT"
   },
   "source": [
    "# **4. Membangun Model Klasifikasi**\n",
    "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
    "\n",
    "Berikut adalah rekomendasi tahapannya.\n",
    "1. Menggunakan algoritma klasifikasi yaitu Decision Tree.\n",
    "2. Latih model menggunakan data yang sudah dipisah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4JYxBe87NLDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training selesai.\n"
     ]
    }
   ],
   "source": [
    "# Buatlah model klasifikasi menggunakan Decision Tree\n",
    "DT = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"Model training selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P_AakAxghYv-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model\n",
    "import joblib\n",
    "joblib.dump(DT, 'decision_tree_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **5. Memenuhi Kriteria Skilled dan Advanced dalam Membangun Model Klasifikasi**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNOEZk24uiXu"
   },
   "source": [
    "**Biarkan kosong jika tidak menerapkan kriteria skilled atau advanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kB_8LIWMATl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training selesai.\n"
     ]
    }
   ],
   "source": [
    "# Melatih model menggunakan algoritma klasifikasi selain Decision Tree.\n",
    "KNN = KNeighborsClassifier().fit(X_train, y_train)\n",
    "SVM = SVC().fit(X_train, y_train)\n",
    "print(\"Model training selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bRlKm5BVAT91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model  Accuracy  Precision    Recall  F1-Score\n",
      "0         Decision Tree (DT)  1.000000   1.000000  1.000000  1.000000\n",
      "1  K-Nearest Neighbors (KNN)  0.996024   0.996048  0.996024  0.996018\n",
      "2                        SVM  1.000000   1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.\n",
    "#Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results = {\n",
    "            'Confusion Matrix': cm, \n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    return results\n",
    "\n",
    "#Mengevaluasi setiap model dan mengumpulkan hasilnya\n",
    "results = {\n",
    "    'Decision Tree (DT)': evaluate_model(DT, X_test, y_test),\n",
    "    'K-Nearest Neighbors (KNN)': evaluate_model(KNN, X_test, y_test),\n",
    "    'SVM': evaluate_model(SVM, X_test, y_test)\n",
    "}\n",
    "\n",
    "#Buat dataframe untuk meringkas hasil \n",
    "sum_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "#Isi dataframe dengan hasil\n",
    "rows = []\n",
    "for model_name, metrics in results.items():\n",
    "    rows.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['Accuracy'],\n",
    "        'Precision': metrics['Precision'],\n",
    "        'Recall': metrics['Recall'],\n",
    "        'F1-Score': metrics['F1-Score']\n",
    "    })\n",
    "\n",
    "#Konversi daftar kamus ke DataFrame\n",
    "sum_df = pd.DataFrame(rows)\n",
    "\n",
    "#Tampilkan DataFrame\n",
    "print(sum_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dUPItkbXBNkO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explore_KNN&SVM_classification.h5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model Selain Decision Tree\n",
    "# Model ini bisa lebih dari satu\n",
    "import joblib\n",
    "joblib.dump([KNN,SVM], 'explore_KNN&SVM_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u23H2guj-h9h"
   },
   "source": [
    "Hyperparameter Tuning Model\n",
    "\n",
    "Pilih salah satu algoritma yang ingin Anda tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dFCTxJJq-m-l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Grid Search): {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
    "\n",
    "#Defenisikan parameter grid untuk GRid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = DT, param_grid = param_grid, cv = 5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_predict = grid_search.predict(X_test)\n",
    "\n",
    "#Output Hasil terbaik\n",
    "print(f\"Best parameters (Grid Search): {grid_search.best_params_}\")\n",
    "best_DT_grid = grid_search.best_estimator_\n",
    "\n",
    "#Evaluasi performa model pada test set\n",
    "grid_search_score = best_DT_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1g6EPSSWxjcQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       172\n",
      "           2       1.00      1.00      1.00       162\n",
      "           3       1.00      1.00      1.00       169\n",
      "\n",
      "    accuracy                           1.00       503\n",
      "   macro avg       1.00      1.00      1.00       503\n",
      "weighted avg       1.00      1.00      1.00       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
    "#print(f\"Accuracy after Grid Search: {grid_search_score:.2f}\")\n",
    "print(classification_report(y_test, grid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Random Search): {'min_samples_split': 2, 'max_depth': 3, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
    "\n",
    "#Defenisikan parameter grid untuk Randomized Search\n",
    "param_dist = {\n",
    "    'max_depth': np.linspace(3, 5, 10, dtype=int),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#Inisialisasi RandomSearchCV\n",
    "random_search = RandomizedSearchCV(estimator = DT, param_distributions = param_dist, n_iter= 20, cv = 5, random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "random_predict = random_search.predict(X_test)\n",
    "\n",
    "#Output Hasil terbaik\n",
    "print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "best_DT_random = random_search.best_estimator_\n",
    "\n",
    "#Evaluasi performa model pada test set\n",
    "random_search_score = best_DT_random.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       172\n",
      "           2       1.00      1.00      1.00       162\n",
      "           3       1.00      1.00      1.00       169\n",
      "\n",
      "    accuracy                           1.00       503\n",
      "   macro avg       1.00      1.00      1.00       503\n",
      "weighted avg       1.00      1.00      1.00       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
    "\n",
    "print(classification_report(y_test, random_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 21, 9]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 44, 9]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['entropy', 25, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 15, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 49, 5]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 25, 7]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['entropy', 15, 10]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['entropy', 44, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 25, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['gini', 39, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['entropy', 40, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['gini', 36, 9]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['gini', 34, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['entropy', 23, 8]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['entropy', 11, 9]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 10, 5] before, using random point ['gini', 25, 6]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riri\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 10, 5] before, using random point ['gini', 36, 9]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Bayes Search): OrderedDict({'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 10})\n"
     ]
    }
   ],
   "source": [
    "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
    "\n",
    "#Defenisikan parameter grid untuk Bayesh Search\n",
    "param_space = {\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (5, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#Inisialisasi BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator = DT, search_spaces = param_space, n_iter = 32, cv = 5, random_state=42)\n",
    "\n",
    "bayes_search.fit(X_train, y_train)\n",
    "bayes_predict = bayes_search.predict(X_test)\n",
    "\n",
    "#Output Hasil terbaik\n",
    "print(f\"Best parameters (Bayes Search): {bayes_search.best_params_}\")\n",
    "best_DT_bayes = bayes_search.best_estimator_\n",
    "\n",
    "#Evaluasi performa model pada test set\n",
    "bayes_search_score = best_DT_bayes.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       172\n",
      "           2       1.00      1.00      1.00       162\n",
      "           3       1.00      1.00      1.00       169\n",
      "\n",
      "    accuracy                           1.00       503\n",
      "   macro avg       1.00      1.00      1.00       503\n",
      "weighted avg       1.00      1.00      1.00       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
    "\n",
    "print(classification_report(y_test, bayes_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7UJNcVP--n7S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuning_classification.h5']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model hasil tuning\n",
    "import joblib\n",
    "joblib.dump([grid_search,random_search,bayes_search], 'tuning_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
